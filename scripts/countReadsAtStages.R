#!/usr/bin/env Rscript

## Copyright (C) 2023 Jonathan D. Magasin

##
## Count reads at each processing stage of the DADA2 pipeline.  Presumes directory
## and file names created by the pipeline.
##

cachedCountFile <- 'readCountsCacheForScript_countReadsAtStages.RData'
usageStr <- paste0(
  "\nUsage:\n",
  "    countReadsAtStages.R  rawFastqDir  trimFastqDir  dada2dir\n\n",
  "Pass the directory that holds FASTQs (for recursive search), the trimmed FASTQs (e.g. from\n",
  "cutadapt),and the directory that holds output from the DADA2 pipeline. This script will make\n",
  "'readCountsDuringProcessing.csv' which shows how many reads were retained at each stage of\n",
  "the pipeline.  It also does a box plot of the same name (.png).\n",
  "The script creates a cache (",cachedCountFile,") that holds the FASTQ read\n",
  "counts at initial, trim, and filter stages of the pipeline, to speed up subsequent runs\n",
  "of this script.\n\n")

args <- commandArgs(trailingOnly=T)
rawFastqDir <- args[1]
if (!dir.exists(rawFastqDir)) { stop("The raw FASTQ directory does not exist.",usageStr) }
trimFastqDir <- args[2]
if (!dir.exists(trimFastqDir)) { stop("The trimmed FASTQ directory does not exist.",usageStr) }
dada2OutDir <- args[3]
if (!dir.exists(dada2OutDir)) { stop("The DADA2 output directory does not exist.",usageStr) }

OUTFILE <- 'readCountsDuringProcessing.csv'
OUTPNG <- 'readCountsDuringProcessing.png'
if (file.exists(OUTFILE)) { stop(OUTFILE," already exists.") }

cat("Loading libraries, please wait...\n")
suppressMessages(library(ShortRead))
suppressMessages(library(dada2))


CountReadsInFastq <- function(dataDir, pattern='\\.fastq\\.gz$')
{
    ## Read with FastqStreamer.  Unfortunately there is no longer countFastq(),
    ## but I hope that the streamer will be a little faster than lapply(, length(readFastq(...)))
    CountOneFQ <- function(fq) {
        strm <- FastqStreamer(fq)
        count <- 0
        repeat {
            n <- length(yield(strm))
            count <- count + n
                if (n == 0) break
                }
                close(strm)
                count
    }
    
    fastqs <- sort(list.files(dataDir, pattern=pattern, full.names=TRUE, recursive=TRUE))
    cat("Reading in",length(fastqs),"FASTQ files from",dataDir,"... \n")
    readsList <- lapply(fastqs, CountOneFQ)
    ## Next step not necessary. Originally I wanted standardized sample names so
    ## that I could track each sample across stages, but I don't need to do that.
    names(readsList) <- gsub(pattern,'',basename(fastqs))
    readsList
}

## Count or load counts for initial reads, reads that passed cutadapt, and reads
## that passed DADA2::filterAndTrim().  Only this part is cached because loading
## in hundreds of FASTQs takes minutes.
if (!file.exists(cachedCountFile)) {
    patTFG <- '\\.trimmed\\.fastq\\.gz$'
    initReads <- CountReadsInFastq(rawFastqDir)
    trimReads <- CountReadsInFastq(trimFastqDir, patTFG)
    ddir <- file.path(dada2OutDir,'filtered')
    filtReads <- CountReadsInFastq(ddir, patTFG)
    save(initReads, trimReads, filtReads, file=cachedCountFile)
} else {
    cat("Loading",cachedCountFile,"\n")
    load(cachedCountFile)
}


cat("Counting merged reads ...\n")
fp <- file.path(dada2OutDir,'RObjects','merged.rds')
if (!file.exists(fp)) {
    cat("There is no merged reads file. Will assume you ran the pipeline\n",
        "using only the R1 reads and so there was no read pair merging.\n")
    mergedReads <- NULL
} else {
    merged <- readRDS(fp)
    mergedReads <- lapply(merged, function(df) { sum(df[which(df$accept),'abundance']) })
    mergedReads <- mergedReads[order(names(mergedReads))]
}


cat("Counting reads in ASVs before chimera detection...\n")
fp <- file.path(dada2OutDir,'RObjects','sequenceTab.rds')
seqTab <- readRDS(fp)  # rows are samples, cols are ASV sequences
asvReads <- rowSums(seqTab)
asvReads <- as.list(asvReads[order(names(asvReads))])


cat("Counting reads in ASVs before after detection...\n")
fp <- file.path(dada2OutDir,'RObjects','sequenceTab.noChimera.rds')
seqTabNoChim <- readRDS(fp)  # rows are samples, cols are ASV sequences
asvNoChimReads <- rowSums(seqTabNoChim)
asvNoChimReads <- as.list(asvNoChimReads[order(names(asvNoChimReads))])


## The id's file is generated by scanASVsForNifH.sh and then manually copied over
## to the corresponding DADA2 output directory.
fp <- file.path(dada2OutDir,'TextData','ids.NifH.txt')
asvWithNifH <- list()
if (file.exists(fp)) {
    cat("Counting reads that are in non-chimeric, NifH+ ASV's\n")
    asvNifH <- read.table(fp)[,1]
    ## Easier to use the tsv than seqTabNoChim
    fp <- file.path(dada2OutDir,'TextData','asvs.noChimera.tsv')
    tab <- read.table(fp)  # asvs are rows, samples are columns
    tab <- tab[intersect(asvNifH, rownames(tab)),]
    if (nrow(tab) > 0) {
        asvWithNifH <- as.list(colSums(tab)) # NifH+ read counts for each sample
    }
}


## Make a data frame amenable to plotting. Do not worry about matching up R1 and
## R2 with the post-merge sample names.
l2df <- function(lst, stage) {
    data.frame(Stage=stage, Sample=names(lst), Reads=as.vector(unlist(lst)))
}
dat <- l2df(initReads,'Initial')
dat <- rbind(dat, l2df(trimReads,'Trimmed'))
dat <- rbind(dat, l2df(filtReads,'Filtered'))
if (!is.null(mergedReads)) {
    dat <- rbind(dat, l2df(mergedReads,'Merged'))
}
dat <- rbind(dat, l2df(asvReads,'InASVs'))
dat <- rbind(dat, l2df(asvNoChimReads,'InNonChimericASVs'))
if (length(asvWithNifH) > 0) {
    dat <- rbind(dat, l2df(asvWithNifH,'InNifHASVs'))
}
write.csv(dat, OUTFILE, row.names=FALSE, quote=FALSE)
cat("Saved",OUTFILE,"\n")


############################################################
##
## Box plot
##
cat("Doing box plot.\n")

dat <- read.csv(OUTFILE, stringsAsFactors=T)
## Note : Sometimes I run on a subset of the samples so Initial > final.
numSamps <- nrow(subset(dat, Stage=='Initial'))/2  # Paired reads

pctRetained <- c()
for (s in as.character(subset(dat, Stage=='InNonChimericASVs')$Sample)) {
    x <- dat[grep(s, dat$Sample),]
    v <- subset(x, Stage=='Initial')[1,'Reads']  # Use R1. Assume R2 Initial is same.
    v <- 100*subset(x, Stage=='InNonChimericASVs')[1,'Reads']/v
    pctRetained <- c(pctRetained, v)
}
rm(s,x,v)

if (!is.null(mergedReads)) {
    ## For a given sample, Merged and InASVs have identical numbers [checked below]
    ## regardless of whether I concatenated or actually merged, because my dada2
    ## script makes the sequence table (corresponds to InASVs) from 'mergers' right
    ## after mergePairs().  So show just one.
    stopifnot( subset(dat, Stage=='Merged')$Reads == subset(dat, Stage=='InASVs')$Reads )
    stages <- c(Initial='Initial', Trimmed='Primers trimmed', Filtered='Quality filtered',
                Merged='In ASVs (merged)', InNonChimericASVs='In non-chimeric ASVs')
} else {
    ## Reads were not merged -- just used the R1's.
    stages <- c(Initial='Initial', Trimmed='Primers trimmed', Filtered='Quality filtered',
                InNonChimericASVs='In non-chimeric ASVs')
}
dat <- subset(dat, Stage %in% names(stages))

dat$Stage <- factor(dat$Stage, levels = rev(names(stages)), labels = rev(stages), ordered=T)

library(ggplot2)
cap <- paste0('Retained MiSeq reads at each stage. Two counts per read pair.  ',
       numSamps,' samples.\n',
       'On average 2x',round(mean(pctRetained),1),'% of the initial reads are merged into final ASVs.')
g <- ggplot(dat,aes(y=Reads, fill=Stage, x=Stage)) + geom_boxplot() + 
     theme_bw() + labs(x='', y='Amplicon sequences', caption=cap) +
     coord_flip()
ggsave(g, filename=OUTPNG, width=6, height=4, units='in', dpi=144)
cat("Saved",OUTPNG,"\n")

quit(save='no')
